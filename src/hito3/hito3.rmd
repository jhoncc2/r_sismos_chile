---
title: "Informe Hito 3: Trabajo con datos sismológicos"
author: "Jhonny Cerezo, Pablo Helguero, Cristián Llull, Rodrigo Llull"
date: "Enero de 2020"
output:
  html_document:
    toc: true
    toc_float: true
    theme: yeti # o readable o default
  pdf_document:
    latex_engine: xelatex
    toc: yes
# Configuraciones del documento pdf
fontsize: 12pt
mainfont: Charter
sansfont: Open Sans
monofont: Liberation Mono
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(reticulate)
use_python("/usr/bin/python3")
library("bookdown")
```

# Introducción

Los sismos en Chile son fenómenos muy recurrentes.
Aun son impredecibles.

Los sismos puden tener consecuencias, por ello, es importante no solo intentar predecir su ocurrencia sino también evaluar el efecto que podrían provocar el sismo en otros ámbitos.
Se decidió indagar si tienen relación con las enfermedades transmitidas por alimentos.
El  poder determinar si existe una relación entre estos eventos podría ayudar a desplegar infraestructura y recursos humanos después de un desastre, además de ayudar en la generación de políticas públicas que ayuden a mitigar los efectos secundarios.

Desde el Hito 2 se trabajan las hipótesis recién mencionadas, puesto que en el Hito 1 se barajó la posibilidad de basarse en 2 estudios principales mencionados posteriormente.
Los análisis realizados finalmente indicaron que no habían tales relaciones o no eran claras para los sismos, por lo menos para Chile.

Conjunto de _dataset_ actualmente utilizado:

_Dataset_             | Objetivo del dataset
--------------------- | --------------------
Datos sismológicos    | Extraer los datos de sismos y poder compararlos con los egresos y las ETAs
Egresos hospitalarios | Dado un sismo, experimentar el aumento o la disminución de egresos hospitalarios
ETAs                  | Dado un sismo, experimentar el aumento o la disminución de enfermedades transmitidas por alimentos.

Las tablas de Egresos hospitalarios y de ETAs tienen mayor cardinalidad que la de datos sismológicos.


## Hipótesis

### Hito 1

Se trabajó con dos estudios principales: el primero, sobre la relación de los sismos con las lluvias monzónicas en el Himalaya, y el segundo, sobre la influencia del sol en ellos.
Los resultados del primer estudio mostraron que la frecuencia de sismos en el Himalaya se veía disminuida con los eventos monzónicos.
Del segundo estudio, se extrajo que los datos sugerían que la mayor cantidad de sismos ocurrían en horarios diurnos.

La expoloración de los datos sugirió que no habían relaciones claras entre los eventos estudiados como para generar un predictor.
En este entendido, se añade al conjunto de _dataset_ una base de datos de egresos hospitalarios, con el fin de direccionar la experimentación a hacia el aumento o la disminución de estos, incluyendo de la misma forma las enfermedades transmitidas por alimentos.

### Hito 2

Se trabajó con los datos de enfermedades transmitidas por alimentos e ingresos hospitalarios.
Se planteraon asimismo hipótesis todavía vigentes:

**Configuración A**: Correlación entre sismos y cantidad de egresos hospitalarios en Chile.

Hipótesis: Los sismos inciden en la cantidad de ingresos hospitalarios por cada región.
Se llegó a que efectivamente existía cierta correlación, pero faltaba indagar más.

**Configuración B**: Correlación entre sismos y cantidad de reportes de enfermedades transmitidas por alimentos en Chile.

Hipótesis: Los sismos inciden en la cantidad de enfermedades transmitidas por alimentos (ETAs), particularmente por deshidratación (como se sugirió con los datos del Hito 1).
Se llegó a que en realidad, había una correlación con la cantidad de ETAs reportadas y los sismos, no en particular por deshidratación.

### Hito 3
Al tratarse de una extensión y mejora del hito 2, no se realiza cambios en las hipótesis ni configuraciones realizadas en el Hito 2.

# Metodología

Se busca juntar los datasets para buscar las correlaciones mencionadas en las hipótesis.
La forma de juntarlos es mediante la posición de los eventos (latitud/longitud) o región, en caso que corresponda, y la fecha en que se produjeron.
De esta manera se buscará la correlación entre los eventos planteados para confirmar o rechazar las hipótesis.



# Descripción de los datos

A continuación se mostrará la descripción de los datos ha utilizar.

## Datos sismológicos

IRIS Incorporated Research Institutions for Seismology o por sus siglas en español, Instituciones incorporadas de investigación sismológica, provee equipamiento y acceso sísmico y otros datos alrededor del mundo, cortesía de una red sismógrafos de la comunidad científica internacional y de Estados Unidos.
Siendo Chile uno de los paises con más frecuencia de sismos en el mundo, IRIS clasifica los sismos dentro de un cuadro limitado por coordenadas definidas por el mismo instituto (máxima latitud=-15.400, mínima latitud=-57.000, máxima longitud=-63.800, mínima lon=-83.100). Como se muestra en el gráfico a continuación:

```{r map, echo=FALSE, message=FALSE}
# Carga de los datos e importacion de librerias
library(ggplot2)
library(dplyr)
library(tidyverse)
library(caret)
library(dplyr)
library(ggmap)

data <- read.delim("../hito2/Datasets sismológicos/all.csv", header = TRUE, sep = "|", quote = "\"",
           dec = ".", fill = TRUE, comment.char = "#")

mapData = tail(data, n=100)
# calculate borders
height <- max(mapData$Latitude) - min(mapData$Latitude)
width <- max(mapData$Longitude) - min(mapData$Longitude)
sac_borders <- c(bottom  = min(mapData$Latitude)  - 0.1 * height, 
                top     = max(mapData$Latitude)  + 0.1 * height,
                left    = min(mapData$Longitude) - 0.1 * width,
                right   = max(mapData$Longitude) + 0.1 * width)

map <- get_stamenmap(sac_borders, zoom = 5, maptype = "toner-lite")
ggmap(map) +
  geom_point(data = mapData, mapping = aes(x = Longitude, y = Latitude,
        col = Depth, size = Magnitude)) +
  scale_color_distiller(palette = "YlOrRd", direction = 1)
```

Dentro de los datos que se utilizaran para el análisis están: longitud, latitud, magnitud, profundidad, y tiempo.
Longitud y latitud son parte del sistema de coordenadas geográficas es un sistema que referencia cualquier punto de la superficie terrestre y que utiliza para ello dos coordenadas angulares, latitud (norte o sur) y longitud (este u oeste).
Magnitud es una medida que tiene relación con la cantidad de energía liberada en forma de ondas.
Profundad define la distancia entre el epicentro de un terremoto con respecto al nivel del mar.
Tiempo es el registro del evento.


### Sismos por estaciones del año

Primero mostramos la gráfica de sismos a través de las estaciones del año tomando en cuenta datos desde el año 1960 hasta el 2019.

```{r, message=FALSE, echo=FALSE}
# load libraries
library(tidyverse)
library(lubridate)

# create new columns 

dtime = as.Date(data$Time)
season_data <-  mutate(data,
  year = year(dtime),
  month = month(dtime),
  mday = mday(dtime)
)

# consider the limitation of seasons simply by looking into range of values
# we bound the seasons by month value, 
# we round the days of the season boundary. E.g. Sept 21 -> OCT

season_data <- mutate(season_data,
  season = case_when (
      month >= 4 & month <= 6 ~ "otonio",
      month >= 7 & month <= 9 ~ "invierno",
      month >= 10 & month <= 12 ~ "primavera",
      month >= 1 & month <= 3 ~ "verano"
    )
) 


# install if needed ggpubr
#install.packages("ggpubr")
library(ggpubr)

bplot <- season_data %>% 
  # filter(year > 2010) %>% 
  ggplot(mapping = aes(x=season)) + 
  geom_bar()

dplot <- season_data %>% 
  group_by(season) %>% 
  summarise(total = n()) %>% 
  ggplot(mapping = aes(x=season, y=total)) +
  geom_point() 

ggarrange(bplot, dplot,
                    ncol = 2, nrow = 1)

```


### Cantidad de datos del dataset

El gráfico de abajo muestra la cantidad de reportes recolectados por año, dentro de las inferencias, y consultas hechas los outliers que puedan ser registrados con equipos antiguos están exentos por ser mínima en su cantidad.

```{r, message=FALSE}
# load libraries
library(tidyverse)
library(lubridate)

# create new columns 

dtime = as.Date(data$Time)
season_data <-  mutate(data,
  year = year(dtime),
  month = month(dtime),
  mday = mday(dtime)
)

# consider the limitation of seasons simply by looking into range of values
# we bound the seasons by month value, 
# we round the days of the season boundary. E.g. Sept 21 -> OCT

season_data <- mutate(season_data,
  season = case_when (
      month >= 4 & month <= 6 ~ "otonio",
      month >= 7 & month <= 9 ~ "invierno",
      month >= 10 & month <= 12 ~ "primavera",
      month >= 1 & month <= 3 ~ "verano"
    )
)

ggplot(season_data, mapping = aes(x=year)) +
  geom_bar()
```


## Datos de precipitaciones fluviales

Los datos fluviales fueron extraídos de la página web de CR2. Fueron tomados desde enero de 1900 hasta febrero de 2018, en 874 estaciones de todo Chile. Existen 2 variantes: la resolución temporal mensual o diaria. Las precipitaciones están medidas en milímetros.

Las dimensiones del dataset corresponden a 874 filas y 1431 columnas, correspondientes a los datos obtenidos en todos los años desde 1900 a 2018, por cada estación. Además, presentan datos como la latitud y longitud de la estación, la altura a la que se encuentra sobre el nivel del mar y la cuenca a la que pertenecen.

Este dataset se dejó de usar para el Hito 3, porque en las iteraciones anteriores no se encontraron correlaciones entre los sismos y las lluvias, por lo que no resultó relevante utilizar técnicas de minería de datos para revisar estos dataset.

```{r}
# Importar dataset de lluvias mensuales
prAmon <- t(read.csv("https://anakena.dcc.uchile.cl/~cllull/IntroMineriaDatos/DataSets/cr2_prAmon_2018/cr2_prAmon_2018.txt"))

colnames(prAmon) <- as.character(unlist(prAmon[1, ])) # Le pone nombre a las columnas
prAmon <- prAmon[-1, ] # Extrae los datos

prAmon_na <- prAmon # Copia de prAmon
prAmon_na[prAmon == -9999] <- NA # Todas las celdas con -9999 a NA
```

Se deben declarar como NA los datos con -9999 que representan datos faltantes, para que R los trabaje de buena manera.

Luego se aplica el promedio de todos los años desde 1900 a 2018, evitando los NA.
```{r}
library(dplyr)
data <- prAmon_na[, 15:1431]  # Los datos de lluvia, sin descripción
data <- as.data.frame(data)  # De matrix a data.frame
data[,] <- apply(data[,], 2, function(x) as.numeric(x)) # Valores de character a numeric
prAmonMean <- prAmon_na[, 1:14]  # Tabla para poner el promedio
prAmonMean <- as.data.frame(prAmonMean)  # De matrix a data.frame
mean <- rowMeans(data, na.rm = TRUE)  # Calcula el promedio
prAmonMean$mean <- mean  # Pone el promedio en la tabla
```

Se separaron los datos por región, debido a que Chile tiene muchos climas diferentes.

```{r}
prAmonMean$latitud <- as.numeric(as.character(prAmonMean$latitud)) # Se debe hacer numérico
prAmonMean_arica <- filter(prAmonMean, latitud <= -17.46 & latitud >= -19.07)
prAmonMean_magallanes <- filter(prAmonMean, latitud < -49.10 & latitud >= -56)
```

Lo más ilustrativo que se puede obtener es determinar las precipitaciones en cada mes del año. De la siguiente forma se extraen las precipitaciones mensuales para la región de Arica:
```{r, message=FALSE, echo=FALSE}
# Datos de arica:
prAmon_na <- as.data.frame(prAmon_na)
prAmon_na$latitud <- as.numeric(as.character(prAmon_na$latitud))
prAmonArica <- filter(prAmon_na, latitud <= -17.46 & latitud >= -19.07)

# Clasificación por meses
prAmonArica_ene <- prAmonArica %>% select(ends_with("01"))
prAmonArica_ene <- apply(prAmonArica_ene, 2, function(x) as.numeric(as.character(x)))
prAmonArica_feb <- prAmonArica %>% select(ends_with("02"))
prAmonArica_feb <- apply(prAmonArica_feb, 2, function(x) as.numeric(as.character(x)))
prAmonArica_mar <- prAmonArica %>% select(ends_with("03"))
prAmonArica_mar <- apply(prAmonArica_mar, 2, function(x) as.numeric(as.character(x)))
prAmonArica_abr <- prAmonArica %>% select(ends_with("04"))
prAmonArica_abr <- apply(prAmonArica_abr, 2, function(x) as.numeric(as.character(x)))
prAmonArica_may <- prAmonArica %>% select(ends_with("05"))
prAmonArica_may <- apply(prAmonArica_may, 2, function(x) as.numeric(as.character(x)))
prAmonArica_jun <- prAmonArica %>% select(ends_with("06"))
prAmonArica_jun <- apply(prAmonArica_jun, 2, function(x) as.numeric(as.character(x)))
prAmonArica_jul <- prAmonArica %>% select(ends_with("07"))
prAmonArica_jul <- apply(prAmonArica_jul, 2, function(x) as.numeric(as.character(x)))
prAmonArica_ago <- prAmonArica %>% select(ends_with("08"))
prAmonArica_ago <- apply(prAmonArica_ago, 2, function(x) as.numeric(as.character(x)))
prAmonArica_sep <- prAmonArica %>% select(ends_with("09"))
prAmonArica_sep <- apply(prAmonArica_sep, 2, function(x) as.numeric(as.character(x)))
prAmonArica_oct <- prAmonArica %>% select(ends_with("10"))
prAmonArica_oct <- apply(prAmonArica_oct, 2, function(x) as.numeric(as.character(x)))
prAmonArica_nov <- prAmonArica %>% select(ends_with("11"))
prAmonArica_nov <- apply(prAmonArica_nov, 2, function(x) as.numeric(as.character(x)))
prAmonArica_dic <- prAmonArica %>% select(ends_with("12"))
prAmonArica_dic <- apply(prAmonArica_dic, 2, function(x) as.numeric(as.character(x)))

prAmonAricaMeses <- prAmonArica[, 1:14]

prAmonAricaMeses$enero <- rowMeans(prAmonArica_ene, na.rm = TRUE)
prAmonAricaMeses$febrero <- rowMeans(prAmonArica_feb, na.rm = TRUE)
prAmonAricaMeses$marzo <- rowMeans(prAmonArica_mar, na.rm = TRUE)
prAmonAricaMeses$abril <- rowMeans(prAmonArica_abr, na.rm = TRUE)
prAmonAricaMeses$mayo <- rowMeans(prAmonArica_may, na.rm = TRUE)
prAmonAricaMeses$junio <- rowMeans(prAmonArica_jun, na.rm = TRUE)
prAmonAricaMeses$julio <- rowMeans(prAmonArica_jul, na.rm = TRUE)
prAmonAricaMeses$agosto <- rowMeans(prAmonArica_ago, na.rm = TRUE)
prAmonAricaMeses$septiembre <- rowMeans(prAmonArica_sep, na.rm = TRUE)
prAmonAricaMeses$octubre <- rowMeans(prAmonArica_oct, na.rm = TRUE)
prAmonAricaMeses$noviembre <- rowMeans(prAmonArica_nov, na.rm = TRUE)
prAmonAricaMeses$diciembre <- rowMeans(prAmonArica_dic, na.rm = TRUE)


library(tidyverse)
prAmonAricaMeses_mean <- gather(prAmonAricaMeses, key="Mes", value="Promedio", enero:diciembre)

prAmonAricaMeses_mean$Mes <- factor(prAmonAricaMeses_mean$Mes, levels = c("diciembre", "noviembre", "octubre", "septiembre", "agosto", "julio", "junio", "mayo", "abril", "marzo", "febrero", "enero"))

ggplot(prAmonAricaMeses_mean) +
  geom_bar(aes(x = Mes, y = Promedio), stat="identity") +
  ggtitle("Promedio de precipitaciones en la región\n
de Arica y Parinacota respecto a cada mes\n") + # título
  theme(axis.text.y = element_text(angle = 30, hjust = 1)) +
  xlab("Mes") + ylab("Promedio precipitaciones") + coord_flip(expand = TRUE)
```


## Datos de temperaturas

Los datos de temperaturas máximas, mínimas y medias fueron extraídos de la página del CR2, al igual que los datos de precipitaciones.
Por esto, tienen la misma clasificación que ellos.


## Datos de registros de ingresos hospitalarios



## Datos de enfermedades transmitidas por alimentos

Los datos de salud alimentaria fueron extraídos de la página web del Departamento de Estadísticas e Información de Salud, en www.deis.cl.
Se extrajeron datos de los brotes de enfermedades transmitidas por alimentos desde el año 2011 hasta el 2017, siendo estos todos los disponibles.

Para hacer una primera exploración de los resultados, se contó la cantidad de casos de enfermedades transmitidas por alimentos reportadas cada año para algunas regiones afectadas por terremotos grandes que ocurrieron en el periodo 2011-2017, aquellos de Iquique el año 2014 y de Illapel el año 2015.

Ahora, los sismos vienen con las columnas _Year_, _Month_ y _Day_, que fueron generados con una función similar a _agregarFechas_ que se encuentra en el anexo.
También incluyen las regiones: estas fueron generadas mediante la función *cargar_sismos_por_region* que se encuentra en el anexo.


### Análisis hitos anteriores

```{r, echo=FALSE}
# Agregarle las fechas a las ETAs
agregarFechasEtas <- function(dataframe) {
  fechas <- as.Date(dataframe$Fecha.de.Ingestión, "%d-%m-%Y")
  fechas <- data.frame(Year=as.numeric(format(fechas, format="%Y")),
                       Month=as.numeric(format(fechas, format="%m")),
                       Day=as.numeric(format(fechas, format="%d")))
  fecha_num <- data.frame(num_date=fechas$Year +
                            (fechas$Month-1)/12 +
                            (fechas$Day-1)/24/12)
  fechas <- cbind(fechas, fecha_num)
  cbind(dataframe, fechas)
}
```

Se cargan los sismos con:
```{r cargarSismos}
sismos <- read.delim("http://anakena.dcc.uchile.cl/~rllull/CC5206/sismos.csv",
                     header = TRUE, sep = ",", quote = "\"", dec = ".", fill = TRUE, comment.char = "#")
```

El código para las ETAs se simplificó mucho, logrando unir los 7 datasets de ETAs en 1.
De esta manera, se cargan los datos de la forma:

```{r cargarEtas}
# Carga de las ETAs
etas <- read.delim("http://anakena.dcc.uchile.cl/~rllull/CC5206/etas2011_2017.csv",
                   header = TRUE, sep = ",", quote = "\"", dec = ".", fill = TRUE, comment.char = "#")

# Agregarle las fechas a las ETAs
etas <- agregarFechasEtas(etas)
```


Después, se guardan los datos en data frames *cant_etas* y *cant_etas_deshidratacion*, para obtener algunos gráficos:

```{r graficosETAs, echo=FALSE}

cant_etas <- data.frame("Año"=etas$Año.estadistico, "Región"=etas$Región.de.consumo,
                        "Cantidad"=etas$Región.de.consumo)
cant_etas <- aggregate(Cantidad ~ Año + Región, cant_etas, function(a) {sum(a>0)})

library(ggplot2)  # cargamos la librería

ggplot(cant_etas[cant_etas$Región == 4, ]) + # asociamos un data frame a ggplot
  geom_bar(aes(x = Año, y = Cantidad), stat="identity") +   # creamos un grafico de barras como una capa
  #coord_flip() +  # transformamos el grafico invirtiendo los ejes de coordenadas (sólo visualmente)
  ggtitle("Reportes de ETA anuales\npara la Región de Coquimbo") + # título
  xlab("Año") + ylab("Cantidad de ETA reportadas ese año")  # etiquetas

ggplot(cant_etas[cant_etas$Región == 1, ]) + # asociamos un data frame a ggplot
  geom_bar(aes(x = Año, y = Cantidad), stat="identity") +   # creamos un grafico de barras como una capa
  #coord_flip() +  # transformamos el grafico invirtiendo los ejes de coordenadas (sólo visualmente)
  ggtitle("Reportes de ETA anuales\npara la Región de Tarapacá") + # título
  xlab("Año") + ylab("Cantidad de ETA reportadas ese año")  # etiquetas

ggplot(cant_etas[cant_etas$Región == 2, ]) + # asociamos un data frame a ggplot
  geom_bar(aes(x = Año, y = Cantidad), stat="identity") +   # creamos un grafico de barras como una capa
  #coord_flip() +  # transformamos el grafico invirtiendo los ejes de coordenadas (sólo visualmente)
  ggtitle("Reportes de ETA anuales\npara la Región de Antofagasta") + # título
  xlab("Año") + ylab("Cantidad de ETA reportadas ese año")  # etiquetas

```


# Pre-procesamiento de los datos

Con el nuevo objetivo definido, se buscó encontrar la correlación que se produce entre los sismos de alta magnitud y los informes de ETA.
Para ello, se decidió utilizar solamente aquellos sismos de magnitud mayor o igual a 5 Mw.

Además, de la misma forma como se hizo en la Exploración de los datos, se clasificaron los sismos por Región de Chile.
De esta manera, se construyó un dataset que tuviera todos los eventos sismológicos disponibles, clasificados por fecha. 


# Limpieza de los datos

## Datos sismológicos

La limpieza de los datos sismológicos se realizó eliminando aquellas columnas que no representaban un verdadero aporte para los casos de estudio.
Para ello, se seleccionaron los atributos de Magnitud, profundidad y región.

De esta forma, se eliminaron todos los otros atributos, dejando datasets más limpios y cómodos de trabajar, en especial para entrenar el clasificador.

La función que se utilizó para realizar esta parte, contó además con el retorno de un dataset que incluía años y meses para un trabajo futuro.

```{r generarDatos}
generar_datos <- function(sismos, etas, magnitud_min, dias, escribir=TRUE) {
  sismos_mag <- sismos[sismos$Magnitude >= magnitud_min
                       & sismos$Year >= 2011 & sismos$Year <= 2017, ]
  # Generar los dataframes
  # datos es para trabajarlo en el árbol de decisión
  datos <- data.frame(Magnitud = rep(0, nrow(sismos_mag)),
                      Profundidad = rep(0, nrow(sismos_mag)),
                      Region = rep(0, nrow(sismos_mag)),
                      Aumento = rep(0, nrow(sismos_mag)))
  # datos_con_fecha es para trabajarlo en lo que viene
  datos_con_fecha <- data.frame(datos,
                              Año = rep(0, nrow(sismos_mag)),
                              Mes = rep(0, nrow(sismos_mag)))
  for (i in 1:nrow(sismos_mag)) {
    sismo <- sismos_mag[i, ]
    # Tomar los dias días anteriores
    etas_ant <- etas[sismo$num_date - dias/30/12 <= etas$num_date
                     & etas$num_date <= sismo$num_date, ]
    # Tomar los 7 días posteriores
    etas_post <- etas[sismo$num_date < etas$num_date
                      & etas$num_date <= sismo$num_date + dias/30/12, ]
    # La diferencia es la cantidad de columnas de las posteriores menos las anteriores
    dif <- nrow(etas_post) - nrow(etas_ant)
    
    # Asignar los valores a los datos
    datos[i, ]$Magnitud <- sismo$Magnitude
    datos[i, ]$Profundidad <- sismo$Depth
    datos[i, ]$Region <- sismo$Region_Number
    # A diferencia del Hito 2, se guarda el Δ completo
    datos[i, ]$Aumento <- dif
    # Guardar datos a retornar
    datos_con_fecha[i, ] <- datos[i, ]
    datos_con_fecha[i, ]$Año <- sismo$Year
    datos_con_fecha[i, ]$Mes <- sismo$Month
    
  }
  # Escribir el csv con los datos obtenidos
  if (escribir) {
    nombre_archivo <- paste("datos_mag", magnitud_min, "_", dias, "d.csv", sep="", collapse=NULL)
    write.csv(datos, nombre_archivo, row.names=FALSE)
  }
  (datos_con_fecha)
}
```

Mediante esta función, entonces, se logró almacenar un _dataset_ para sismos, indicando en la columna Aumento el Δ: la diferencia entre cuántas ETAs se registraron los _dias_ días posteriores al sismo y los _dias_ días anteriores al sismo.



# Minería de datos

Dada la estructura de los datos, se diseñaron clasificadores en la forma de árboles de decisión.
Así, se podrían identificar los atributos que el clasificador pudiera considerar importantes para hacer la predicción.


## Diseño experimental

### Enfermedades de transmisión alimentaria

Para generar correctamente un modelo de clasificación, se necesitó pensar en un procedimiento efectivo que dijera con certeza si un terremoto realmente provocó daños.
Esto, con base en la hipótesis de que mientras más daños pueda generar un sismo, más informes por ETAs se generan.
Además, se debió agregar la dimensión de temporalidad, necesaria para apreciar los datos.

De esta manera, se pensó en lo siguiente: si en los _n_ días antes del sismo se registraron menos informes por ETA que en los _n_ días después, quiere decir que el sismo aumentó los informes y por ende los daños.
De lo contrario, los disminuyó.
Este valor se denominó Δ, con $\Delta = etas_{post} - etas_{ant}$.

En el Hito 2 se representó con un 1 si el Δ era positivo, y un 0 si era negativo.
El nuevo Δ permitió aumentar la cantidad de clases a estudiar.

Luego, se realizó el árbol de decisión.
El experimento consistió en generar un GridSearchCV de DecisionTree para criterios criterion gini y entropy, mientras que con una profundidad máxima de entre 1, 3 y 5 para los árboles generados.

Esto se realizó en Python 3 mediante la librería `sklearn`.
Se generaron archivos de texto que almacenaran los resultados para los distintos árboles.

![Imagen de cómo se calculó _aumento_](Imágenes/aumento.jpg)


#### Determinación del umbral para clasificador de ETAs

Para el nuevo clasificador, fue necesario determinar un umbral con tal de definir la disminución marcada, la disminución tenue, el aumento tenue y el aumento marcado.

Se cargan los datos con la función *generar_datos*, de la forma
```{r}
mag4_7d <- generar_datos(sismos, etas, 4, 7, escribir=FALSE)
```

Luego se determinó el número para el umbral observando el comportamiento parecido a una distribución normal observado para los datos de magnitud 5
```{r}
quantile(mag4_7d$Aumento, prob=seq(0, 1, length = 11))
```


#### Extracción de los sismos y sus Δs

Se extraen para diferentes magnitudes (5, 6 y 7) e intervalos (de 3, 7, 14 y 30 días).
Se crea una función para trabajar los datos más fácil.

```{r}
generar_datos <- function(sismos, etas, magnitud_min, dias, escribir=TRUE) {
  sismos_mag <- sismos[sismos$Magnitude >= magnitud_min
                       & sismos$Year >= 2011 & sismos$Year <= 2017, ]
  # Generar los dataframes
  # datos es para trabajarlo en el árbol de decisión
  datos <- data.frame(Magnitud = rep(0, nrow(sismos_mag)),
                      Profundidad = rep(0, nrow(sismos_mag)),
                      Region = rep(0, nrow(sismos_mag)),
                      Aumento = rep(0, nrow(sismos_mag)))
  # datos_con_fecha es para trabajarlo en lo que viene
  datos_con_fecha <- data.frame(datos,
                              Año = rep(0, nrow(sismos_mag)),
                              Mes = rep(0, nrow(sismos_mag)))
  for (i in 1:nrow(sismos_mag)) {
    sismo <- sismos_mag[i, ]
    # Tomar los dias días anteriores
    etas_ant <- etas[sismo$num_date - dias/30/12 <= etas$num_date
                     & etas$num_date <= sismo$num_date, ]
    # Tomar los 7 días posteriores
    etas_post <- etas[sismo$num_date < etas$num_date
                      & etas$num_date <= sismo$num_date + dias/30/12, ]
    # La diferencia es la cantidad de columnas de las posteriores menos las anteriores
    dif <- nrow(etas_post) - nrow(etas_ant)
    
    # Asignar los valores a los datos
    datos[i, ]$Magnitud <- sismo$Magnitude
    datos[i, ]$Profundidad <- sismo$Depth
    datos[i, ]$Region <- sismo$Region_Number
    # A diferencia del Hito 2, se guarda el Δ completo
    datos[i, ]$Aumento <- dif
    # Guardar datos a retornar
    datos_con_fecha[i, ] <- datos[i, ]
    datos_con_fecha[i, ]$Año <- sismo$Year
    datos_con_fecha[i, ]$Mes <- sismo$Month
    
  }
  # Escribir el csv con los datos obtenidos
  if (escribir) {
    nombre_archivo <- paste("datos_mag", magnitud_min, "_", dias, "d.csv", sep="", collapse=NULL)
    write.csv(datos, nombre_archivo, row.names=FALSE)
  }
  (datos_con_fecha)
}
```

Para generar los datos, se procedió de la siguiente forma:

```{r}
# Sismos de magnitud mayor o igual a 5
mag5_3d <- generar_datos(sismos, etas, 5, 3)
mag5_7d <- generar_datos(sismos, etas, 5, 7)
mag5_14d <- generar_datos(sismos, etas, 5, 14)
mag5_30d <- generar_datos(sismos, etas, 5, 30)

# Sismos de magnitud mayor o igual a 6
mag6_3d <- generar_datos(sismos, etas, 6, 3)
mag6_7d <- generar_datos(sismos, etas, 6, 7)
mag6_14d <- generar_datos(sismos, etas, 6, 14)
mag6_30d <- generar_datos(sismos, etas, 6, 30)

# Sismos de magnitud mayor o igual a 7
mag7_3d <- generar_datos(sismos, etas, 7, 3)
mag7_7d <- generar_datos(sismos, etas, 7, 7)
mag7_14d <- generar_datos(sismos, etas, 7, 14)
mag7_30d <- generar_datos(sismos, etas, 7, 30)
```

#### Aumento registrado según la región

Procedemos a hacer un _aggregate_ con tal de contar cuánto aumentó, en promedio, por cada magnitud y por cada región.
Además, se puede extraer si se aprecia un aumento según cada magnitud y cada intervalo, obteniendo un resultado en cantidad de ETAs registradas posteriores o anteriores al sismo en promedio.

```{r, message=FALSE}
# Magnitud 5 o más
agg_5_3d <- aggregate(Aumento ~ Region, mag5_3d, FUN=mean)
(agg_5_7d <- aggregate(Aumento ~ Region, mag5_7d, FUN=mean))
agg_5_14d <- aggregate(Aumento ~ Region, mag5_14d, FUN=mean)
agg_5_30d <- aggregate(Aumento ~ Region, mag5_30d, FUN=mean)

# Aumnento promedio por intervalo considerado para mgnitud mayor o igual a 5
promedios <- 0
promedios[1, 1] <- mean(mag5_3d$Aumento)
promedios[1, 2] <- mean(mag5_7d$Aumento)
promedios[1, 3] <- mean(mag5_14d$Aumento)
promedios[1, 4] <- mean(mag5_30d$Aumento)

# Magnitud 6 o más
agg_6_3d <- aggregate(Aumento ~ Region, mag6_3d, FUN=mean)
(agg_6_7d <- aggregate(Aumento ~ Region, mag6_7d, FUN=mean))
agg_6_14d <- aggregate(Aumento ~ Region, mag6_14d, FUN=mean)
agg_6_30d <- aggregate(Aumento ~ Region, mag6_30d, FUN=mean)

# Aumento promedio por intervalo considerado para magnitud mayor o igual a 6
promedios[2, 1] <- mean(mag6_3d$Aumento)
promedios[2, 2] <- mean(mag6_7d$Aumento)
promedios[2, 3] <- mean(mag6_14d$Aumento)
promedios[2, 4] <- mean(mag6_30d$Aumento)

# Magnitud 7 o más
agg_7_3d <- aggregate(Aumento ~ Region, mag7_3d, FUN=mean)
(agg_7_7d <- aggregate(Aumento ~ Region, mag7_7d, FUN=mean))
agg_7_14d <- aggregate(Aumento ~ Region, mag7_14d, FUN=mean)
agg_7_30d <- aggregate(Aumento ~ Region, mag7_30d, FUN=mean)

# Aumnento promedio por intervalo considerado para mgnitud mayor o igual a 5
promedios[3, 1] <- mean(mag7_3d$Aumento)
promedios[3, 2] <- mean(mag7_7d$Aumento)
promedios[3, 3] <- mean(mag7_14d$Aumento)
promedios[3, 4] <- mean(mag7_30d$Aumento)
```


## Clasificadores de enfermedades de transmisión alimentaria

De acuerdo a lo observado en la sección anterior, se justifica realizar un clasificador, debido a que se logran apreciar algunos clusters relacionados con la profundidad y la magnitud del sismo y el aumento de los ingresos por enfermedades de transmisión alimentaria.
Además, se observó que, con sismos mayores o iguales a magnitud 6, los ingresos aumentaban y se mantenían en un valor positivo de diferencia respecto a la cantidad posterior al sismo y anterior a él.
Con los magnitud 7 se observó un aumento de los ingresos post sismo siempre.

### Clasificador de árbol de decisión

#### Competencia de árboles de decisión

### Competencia de clasificadores

## Cambio en la forma de medir los ingresos hospitalarios

### Experimentación con los clasificadores expuestos anteriormente

## Resultados

# Anexo


### Ingresos hospitalarios


# Resultados

## Clasificador para enfermedades de transmisión alimentaria


## Clasificador para ingresos hospitalarios


# Anexo

```{r agregarFechas}
# Agregarle las fechas a las ETAs
agregarFechasEtas <- function(dataframe) {
  fechas <- as.Date(dataframe$Fecha.de.Ingestión, "%d-%m-%Y")
  fechas <- data.frame(Year=as.numeric(format(fechas, format="%Y")),
                       Month=as.numeric(format(fechas, format="%m")),
                       Day=as.numeric(format(fechas, format="%d")))
  fecha_num <- data.frame(num_date=fechas$Year +
                            (fechas$Month-1)/12 +
                            (fechas$Day-1)/24/12)
  fechas <- cbind(fechas, fecha_num)
  cbind(dataframe, fechas)
}
```


